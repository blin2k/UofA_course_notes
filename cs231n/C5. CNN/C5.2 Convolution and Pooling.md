Instead of flatten the image into a column, in Convolutional Neural Networks, we keep the spatial structure of the image.

![[Pasted image 20241006183408.png]]
Use a filter that has the same depth as the image to run over the whole image

![[Pasted image 20241006183515.png]]
It is still a linear dot product between flatten blocks.

![[Pasted image 20241006183926.png]]
Slide the filter pixel by pixel, we can have a activation map.

Hyperparameter
- The size of the filter
- The step size of the filter
	- Stride

![[Pasted image 20241006184421.png]]
We can have multiple layers
![[Pasted image 20241006184658.png]]
Each filter represents some low-level features that we are looking for.
![[Pasted image 20241006184912.png]]

The visualization of W in linear classification looks like a template of the class. We've talked about the flaw of this design.
In fact, the visualization of each filter will look like a small feature, for example, an edge, a dot. When passing out, the next layer will look like a feature that a bit more complex, like a wheel or a light.
Each activation map shows the "score" on that specific feature.

![[Pasted image 20241006191154.png]]
![[Pasted image 20241006191811.png]]
Sometimes, a filter-stride pair won't fit the image ($N-F\, mod\,stride\not=0$)). For example, a 3 by 3 filter with stride 3 on a 7 by 7 image.
Padding zeros can solve the problem. It can also help you get a full size map, otherwise the size of the layer will shrink very quick.

We can also use 1 by 1 filters to decrease the depth.
![[Pasted image 20241006194545.png]]
